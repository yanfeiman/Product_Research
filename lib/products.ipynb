{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2710,"status":"ok","timestamp":1717231207825,"user":{"displayName":"Amy Weng","userId":"14843724886946958321"},"user_tz":-480},"id":"RcQ3qPmz29Wb"},"outputs":[],"source":["import requests\n","from tqdm import tqdm \n","import pandas as pd\n","import os, json\n","import sys\n","sys.path.append(\"../\")\n","\n","materials = ['moissanite','birthstone',\n","             'cubic zirconia',\n","             'sterling silver',\n","             # I added these gold-related ones based on the commonly occuring phrases in the titles of in top products \n","             \"solid gold\", \"gold plated\", \n","             # crystals \n","             # see https://www.holisticshop.co.uk/crystals/popular-crystals\n","             'amethyst','aquamarine','lapis lazuli',\n","            'moonstone','pearl','peridot',\n","            'jade','citrine','rose quartz','tourmaline',\n","             'blue lace agate','sunstone','clear quartz',\n","             'aura quartz','black agate','black jasper',\n","             'agate','aventurine','calcite','carnelian','fluorite',\n","             'hematite','jasper','labradorite','malachite','moldavite',\n","             'obsidian','opalite','selenite','shungite',\"tiger's eye\",\n","             'turquoise','orgone','topaz','garnet','lepidolite','smoky quartz']\n","\n","data = pd.read_csv(f\"../data/ID_TO_NAME.csv\")\n","all_id_to_name = {str(cat_id): data['name'][idx] for idx, cat_id in enumerate(data['id']) }\n","\n","with open(f\"../data/categories/Jewelry.json\",\"r\") as file: \n","    jewelry_ids, jewelry_paths = json.load(file)\n","\n","with open(f\"../data/categories/Violin.json\",\"r\") as file: \n","    violin_ids, violin_paths = json.load(file)\n","\n","with open(f\"../data/categories/Nails.json\",\"r\") as file: \n","    nail_ids, nail_paths = json.load(file)"]},{"cell_type":"markdown","metadata":{"id":"XzDJREcuuATb"},"source":["### Search Products"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717144989744,"user":{"displayName":"Amy Weng","userId":"14843724886946958321"},"user_tz":-480},"id":"9ZAhI6_mRK8t"},"outputs":[],"source":["cols = ['asin', 'price', 'title', 'rating', 'currency', \n","        'is_prime', 'best_seller', 'price_upper', \n","        'is_sponsored', 'manufacturer', 'sales_volume', \n","        'pricing_count', 'reviews_count', 'is_amazons_choice', \n","        'price_strikethrough', 'shipping_information','pos', 'rel_pos',\n","        'url_image']\n","\n","sources = ['paid','organic','suggested','amazons_choices']\n","\n","class Amazon_Search():\n","    def __init__(self,category_id,keywords,total_num_pages=7):\n","        self.domain = \"com\"\n","        self.category_id = category_id\n","        self.search_results = {} \n","        progress = tqdm(keywords)\n","        for query in progress: \n","            self.search_results[query] = []\n","            for page in range(total_num_pages):\n","                progress.set_description_str(f\"Processing {self.category_id} {all_id_to_name[category_id]}: {query} page {page}\") \n","                results = self.search(query,page)\n","                if len(results['results']) == 0: \n","                    break\n","                self.search_results[query].append(results['results'])\n","            self.save_data()  \n","        \n","    def search(self,query,page):\n","        task_params = {\n","            \"target\": \"amazon_search\",\n","            \"query\": query,\n","            \"domain\": self.domain, # USA \n","            \"page_from\": page, # from 1 to 7 (already the most likely to be viewed by customers)\n","            \"category\": self.category_id, \n","            \"parse\": True\n","        }\n","\n","        username = \"U0000179330\" # os.environ.get('API_USERNAME')\n","        password = \"8e2PtjAOUj2_isx9hy\" # os.environ.get('API_PASSWORD')\n","        response = requests.post(\n","            'https://scraper-api.smartproxy.com/v2/scrape',\n","            json = task_params,\n","            auth = (username, password)\n","        )\n","\n","        return response.json()\n","\n","    def save_data(self):\n","        all_results = []\n","        def product(p,page,query,abs_pos,source):\n","            d = {}\n","            for c in cols: \n","                if c in p: \n","                    d[c] = p[c]\n","                else: \n","                    d[c] = None\n","            d['source'] = source\n","            d['category_id'] = self.category_id\n","            d['keyword'] = query \n","            d['page'] = page + 1\n","            d['position'] = abs_pos+1\n","            d['min_revenue'],d['discount'],d['discount_rate'] = 0,0,0\n","            if d['reviews_count'] is not None and d['price'] is not None: \n","                d['min_revenue'] = d['reviews_count']*d['price']\n","            if d['price_strikethrough'] is not None: \n","                d['discount'] = d['price_strikethrough'] - d['price']\n","                d['discount_rate'] = d['discount'] / d['price_strikethrough']\n","            else: \n","                d['price_strikethrough'] = 0\n","            return d \n","\n","        for query, results in self.search_results.items(): \n","            pages = [p[0]['content']['results'] for p in results]\n","\n","            source_idx = {source:0 for source in sources}\n","            for pnum, page in enumerate(pages):\n","                if len(page['results']) == 0: continue\n","                for source in sources:\n","                    products = page['results'][source]\n","                    for p in products:\n","                        all_results.append(product(p,pnum,query,source_idx[source],source))\n","                        source_idx[source] += 1 \n","            df = pd.DataFrame(all_results)\n","            df.to_csv(f'../data/search_results/{self.category_id}_{all_id_to_name[self.category_id]}.csv', index=False)\n","                \n","        df = pd.DataFrame(all_results)\n","        df.to_csv(f'../data/search_results/{self.category_id}_{all_id_to_name[self.category_id]}.csv', index=False)\n","\n","import pandas as pd \n","data = pd.read_csv(f\"../data/ID_TO_NAME.csv\")\n","all_id_to_name = {str(cat_id): data['name'][idx] for idx, cat_id in enumerate(data['id']) }\n","\n","def process_results(ids, keywords,num_pages=7):\n","    if keywords is None: search_cat = True \n","    else: search_cat = False \n","    for cat_id in ids:\n","        if search_cat: keywords = [all_id_to_name[cat_id].lower()]\n","        Amazon_Search(cat_id,keywords,num_pages)   "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["searchterms = ['electronic cigarettes','e-cigarettes','smokeless inhaler','herbal cigarettes']\n","search_results = process_results([\"4078751\"],searchterms)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["search_results = process_results(violin_ids,['violin'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["search_results = process_results(jewelry_ids[11:12],materials[14:],num_pages=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["search_results = process_results(jewelry_ids[12:],materials,num_pages=1)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing 17269952011 Base Coat: base coat page 6: 100%|██████████| 1/1 [00:17<00:00, 17.51s/it]\n","Processing 11059361 Combination Base & Top Coats: combination base & top coats page 6: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it]\n","Processing 17269951011 Top Coat: top coat page 6: 100%|██████████| 1/1 [00:24<00:00, 24.38s/it]\n","Processing 13861682011 Acrylic Nail Tools: acrylic nail tools page 6: 100%|██████████| 1/1 [00:22<00:00, 22.46s/it]\n","Processing 17269962011 Acrylic Powders & Liquids: acrylic powders & liquids page 6: 100%|██████████| 1/1 [00:20<00:00, 20.07s/it]\n","Processing 3784781 False Nails: false nails page 6: 100%|██████████| 1/1 [00:14<00:00, 14.43s/it]\n","Processing 17269963011 Nail Glue: nail glue page 6: 100%|██████████| 1/1 [00:18<00:00, 18.96s/it]\n","Processing 13861684011 Nail Tips: nail tips page 6: 100%|██████████| 1/1 [00:24<00:00, 24.48s/it]\n","Processing 13106421 Nail Art Equipment: nail art equipment page 6: 100%|██████████| 1/1 [00:12<00:00, 12.30s/it]\n","Processing 17269953011 Decoration Kits: decoration kits page 6: 100%|██████████| 1/1 [00:18<00:00, 18.12s/it]\n","Processing 17269954011 Fimo: fimo page 6: 100%|██████████| 1/1 [00:17<00:00, 17.97s/it]\n","Processing 17269955011 Glitters: glitters page 6: 100%|██████████| 1/1 [00:16<00:00, 16.28s/it]\n","Processing 17269956011 Pearls: pearls page 6: 100%|██████████| 1/1 [00:16<00:00, 16.73s/it]\n","Processing 17269957011 Rhinestones: rhinestones page 6: 100%|██████████| 1/1 [00:25<00:00, 25.61s/it]\n","Processing 17269958011 Stickers & Decals: stickers & decals page 6: 100%|██████████| 1/1 [00:18<00:00, 18.31s/it]\n","Processing 17269959011 Striping Tape Lines: striping tape lines page 6: 100%|██████████| 1/1 [00:16<00:00, 16.56s/it]\n","Processing 17269960011 Studs: studs page 6: 100%|██████████| 1/1 [00:15<00:00, 15.75s/it]\n","Processing 17269961011 Wraps: wraps page 6: 100%|██████████| 1/1 [00:18<00:00, 18.14s/it]\n"]}],"source":["process_results(nail_ids,None)"]},{"cell_type":"markdown","metadata":{"id":"Eav1Ai7Xs95H"},"source":["### Prices and approximate sales & revenue (if known)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pprint import pprint\n","import statsmodels.api as sm\n","\n","class Stats():\n","  def __init__(self,products,keyword=None):\n","      # Dictionary of the original entries in the aggregated CSV for each collection of search terms (i.e., keyword)\n","      if keyword is not None: \n","          products = products[products.keyword == keyword]\n","      self.keyword = keyword\n","      self.category_id = products['category_id'][0] \n","      products = products.to_dict(orient='records')\n","      self.products = {info['asin']: info for info in products}\n","      \n","      # Dictionary of dictionaries with central tendency statistics for each metric\n","      self.stats = {}\n","\n","      # Dictionary mapping ASIN to a certain type of info\n","      self.prices = {}\n","      self.rating = {}\n","      self.reviews_count, self.sales = {}, {}\n","      self.best_sellers, self.prime, self.choice,self.sponsored = {},{},{},{}\n","      self.min_revenue_all = {}\n","      self.discounts, self.percentages = {}, {}\n","      for asin, info in self.products.items():\n","          self.prices[asin] = info['price']\n","          self.min_revenue_all[asin] = info['min_revenue']\n","          self.rating[asin] = info['rating']\n","          self.reviews_count[asin] = info['reviews_count']\n","          if info['price_strikethrough'] > 0:\n","              self.discounts[asin] = info['discount'] \n","              self.percentages[asin] = info['discount_rate']\n","          if info['best_seller']: self.best_sellers[asin] = None\n","          if info['is_prime']: self.prime[asin] = None\n","          if info['is_sponsored']: self.sponsored[asin] = None\n","          if info['is_amazons_choice']: self.choice[asin] = None\n","\n","          if isinstance(info['sales_volume'],str):\n","              if '+' not in info['sales_volume']: continue \n","              self.pastmonth = info['sales_volume'].split(\"+\")[0]\n","              if 'K' in self.pastmonth:\n","                self.pastmonth = 1000 * int(self.pastmonth.split(\"K\")[0])\n","              self.sales[asin] = int(self.pastmonth)\n","\n","      print(f'''There are {len(self.prices)} products with reviews:\n","            {len(self.sales)} with approximate sales volume for the past month,\n","            {len(self.best_sellers)} in Best Sellers,\n","            {len(self.choice)} in Amazon's Choice,\n","            {len(self.prime)} in Prime,\n","            {len(self.sponsored)} paid products in the search results, and\n","            {len(self.discounts)} products with price changes.''')\n","      \n","      self.all_stats('Organic')\n","      self.all_stats('Paid')\n","\n","  def get_stats(self, key, dictionary):\n","    #   if key in self.stats:\n","        #   print(self.stats[key])\n","        #   return\n","      search_type, product_type, title = key.split(\" - \")\n","      data = pd.Series(dictionary)\n","      mean = round(data.mean(),2)\n","      median = round(data.median(),2)\n","      if len(data.mode()) > 0:  \n","        mode = round(data.mode()[0],2)\n","        modefreq = data.value_counts()[data.mode()[0]]\n","        stdev = round(data.std(),2)\n","        max = round(data.max(),2)\n","        min = round(data.min(),2)\n","        percentiles = data.quantile([0.25, 0.75])\n","        self.stats[key] = {'Title': title, 'Category ID': self.category_id, \n","                          'Keyword': self.keyword, 'Search Type': search_type, \n","                          'Product Type':product_type, 'Mean': mean, 'Median': median, \n","                          'Mode': mode, 'Mode Freq': modefreq, 'Std Dev': stdev,\n","                          'Max': max, 'Min': min,'Percentile25':round(percentiles[0.25],2),\n","                          'Percentile75':round(percentiles[0.75],2)}\n","    #   pprint(self.stats[key])\n","\n","  def all_stats(self,category='Organic'):\n","\n","      def get_relevant(dictionary,type='All'):\n","          min_rev, prices_relevant = {},{}\n","          ratings, reviews = {},{}\n","          discounts, percentages = {},{}\n","          for asin, item in dictionary.items():\n","              if category == 'Organic':\n","                if asin in self.sponsored: continue\n","              elif category == \"Paid\":\n","                if asin not in self.sponsored: continue\n","              min_rev[asin] = self.min_revenue_all[asin]\n","              prices_relevant[asin] = self.prices[asin]\n","              ratings[asin] = self.rating[asin]\n","              reviews[asin] = self.reviews_count[asin]\n","              if asin in self.discounts: \n","                discounts[asin] = self.discounts[asin]\n","                percentages[asin] = self.percentages[asin]\n","          self.get_stats(f'{category} - {type} - Revenue',min_rev)\n","          self.get_stats(f'{category} - {type} - Price',prices_relevant)\n","          self.get_stats(f'{category} - {type} - Rating',ratings)\n","          self.get_stats(f'{category} - {type} - Reviews Count',reviews)\n","          self.get_stats(f'{category} - {type} - Amount Discounted',discounts)\n","          self.get_stats(f'{category} - {type} - Percent Discounted',percentages)\n","\n","      get_relevant(self.reviews_count)\n","      get_relevant(self.best_sellers,\"Best Seller\")\n","      get_relevant(self.sales,\"Past Month Sales Volume\")\n","      get_relevant(self.prime,\"Prime\")\n","      get_relevant(self.choice,\"Amazon's Choice\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["searches = os.listdir('../data/search_results')\n","stats = []\n","for file in searches:  \n","    products = pd.read_csv(f'../data/search_results/{file}')\n","    for keyword in set(products.keyword): \n","        print(f\"Processing {file}\")\n","        product_stats = Stats(products,keyword)\n","        stats.extend(list(product_stats.stats.values()))\n","        print()\n","pd.DataFrame(stats).to_csv(f'../data/product_stats.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def logit_regression(products):\n","    data = {'price':[],'reviews_count':[],'min_revenue':[],'discount_rate':[],\n","            'choice':[],'prime':[],\n","            'sponsored':[],\n","            'high_sales':[]}\n","    for p in products:\n","        if p['reviews_count'] == 0 or p['price'] == 0: continue\n","\n","        if p['is_sponsored']: data['sponsored'].append(1)\n","        else: data['sponsored'].append(0)\n","\n","        if p['is_prime']: data['prime'].append(1)\n","        else: data['prime'].append(0)\n","\n","        if p['is_amazons_choice']: data['choice'].append(1)\n","        else: data['choice'].append(0)\n","\n","        if p['discount_rate'] > 0: data['discount_rate'].append(p['discount_rate'])\n","        else: data['discount_rate'].append(0.0)\n","\n","        data['price'].append(p['price'])\n","        data['reviews_count'].append(p['reviews_count'])\n","        data['min_revenue'].append(p['min_revenue'])\n","\n","        # dependent variable\n","        if p['best_seller'] == True or isinstance(p['sales_volume'],str): data['high_sales'].append(1)\n","        else: data['high_sales'].append(0)\n","    \n","    if sum(data['high_sales']) == 0: \n","        return \n","    \n","    df = pd.DataFrame(data)\n","    X = df.drop('high_sales', axis=1)\n","    y = df['high_sales']\n","    logit_model = sm.Logit(y, X).fit()\n","    print(logit_model.summary())\n","    return X, y"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["searches = os.listdir('../data/search_results')\n","products = []\n","for file in searches:  \n","    data = pd.read_csv(f'../data/search_results/{file}')\n","    products.extend(data.to_dict('records'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.DataFrame(products)\n","df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n","\n","def combine_elements(series):\n","    return '; '.join(series.astype(str).unique())\n","combine_columns = ['position', 'keyword','category_id']\n","keep_columns = [col for col in df.columns if col not in combine_columns and col != 'asin']\n","PRODUCTS = df.groupby(['asin']).agg(\n","    {**{col: combine_elements for col in combine_columns},\n","     **{col: 'first' for col in keep_columns}}\n",").reset_index()\n","\n","PRODUCTS = PRODUCTS.sort_values(by=[\"min_revenue\",\"best_seller\",\"rating\",\"reviews_count\"],ascending=[False,True,False,False])\n","\n","\n","def get_url(asin):\n","    return f\"https://www.amazon.com/dp/{asin}\"\n","PRODUCTS['url'] = PRODUCTS['asin'].apply(get_url)\n","def sales_vol(info):\n","    if info is None: return None\n","    num = info.split(\"bought in past month\")[0]\n","    num = num.split(\"+\")[0]\n","    if \"K\" in num: \n","        num = num.split(\"K\")[0] \n","        return f\"{int(num)*1000}+\"\n","    return f\"{num}+\" \n","PRODUCTS['sales_volume'] = PRODUCTS['sales_volume'].apply(sales_vol)\n","\n","def round_values(value):\n","    return round(value,2)\n","PRODUCTS['discount_rate'] = PRODUCTS['discount_rate'].apply(round_values)\n","PRODUCTS['discount'] = PRODUCTS['discount'].apply(round_values)\n","PRODUCTS['min_revenue'] = PRODUCTS['min_revenue'].apply(round_values)\n","\n","\n","def set_to_zero(value):\n","    if pd.isna(value): return 0 \n","    else: return value \n","\n","PRODUCTS['discount'] = PRODUCTS['discount'].apply(set_to_zero)\n","PRODUCTS['discount_rate'] = PRODUCTS['discount_rate'].apply(set_to_zero)\n","PRODUCTS = PRODUCTS[PRODUCTS[\"min_revenue\"] > 0.0]\n","PRODUCTS.to_csv('../data/products.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X, y = logit_regression(products)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":410,"status":"ok","timestamp":1717229744268,"user":{"displayName":"Amy Weng","userId":"14843724886946958321"},"user_tz":-480},"id":"COXE1b5MCBAW"},"outputs":[],"source":["model = LogisticRegression() \n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","model.fit(x_train, y_train)\n","predictions = model.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Logistic Regression with 3:1 train-test split\n","target_names = ['not high sales', 'high sales']\n","print(classification_report(y_test, predictions, target_names=target_names))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPeXg6MvTtmhypXVKUilfWO","collapsed_sections":["XzDJREcuuATb"],"mount_file_id":"1UfrJggu8i09ahuMiqNE0BOBFlxhvmuqw","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
