{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape and save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Categories():\n",
    "    def __init__(self,target=None):\n",
    "        self.target = target # either None or (id,name)\n",
    "        self.website = 'https://www.browsenodes.com/amazon.com'\n",
    "        self.level = 0 # category level; 0 level ones are the main root categories \n",
    "        self.edges = {self.level:[]} # level: (parent_id, child_id)\n",
    "        self.id_to_name = {} \n",
    "\n",
    "\n",
    "        if target is None: # get the names of all the main categories (41 in total) \n",
    "            self.n = 4 # <name> <id> <name> <url> format for the home page \n",
    "            result = requests.get(self.website)\n",
    "            content = result.text\n",
    "            soup = BeautifulSoup(content, 'lxml')\n",
    "            self.get_info(soup)\n",
    "        elif len(target) == 2: # start from a child node \n",
    "            self.n = 3 # <name> <id> <url> format for all other subpages\n",
    "            result = requests.get(self.get_url(self.target))\n",
    "            if not re.search(r\"^\\d+$\",target[0]):\n",
    "                print(\"Error: please enter the category id as the first element of target.\")\n",
    "            else: \n",
    "                self.id_to_name[target[0]] = target[1]\n",
    "                self.edges[0].append((None,self.target[0])) \n",
    "        else: \n",
    "            print(\"Error: please enter target in the right format.\")\n",
    "        # print(self.edges, self.id_to_name)\n",
    "\n",
    "    def num_children(self):\n",
    "        num = 0 \n",
    "        for p,c in self.edges[self.level]:\n",
    "            if c is not None: \n",
    "                num += 1 \n",
    "        return num\n",
    "\n",
    "    def get_url(self, category_id):\n",
    "        return f\"{self.website}/browseNodeLookup/{category_id}.html\"\n",
    "\n",
    "    def get_info(self,soup,parent_id=None):\n",
    "        newlevel = self.level + 1 \n",
    "        table = soup.find_all(\"td\") # entries of the data table on the website page \n",
    "        if len(table) == 0: # no data \n",
    "            self.edges[newlevel].append((parent_id,None))\n",
    "        elif \"is a leaf node\" in table[0].text: # reached a leaf node \n",
    "            self.edges[newlevel].append((parent_id,None))\n",
    "        else:     # there exist children \n",
    "            curr_id, curr_name = None, None\n",
    "            for idx, entry in enumerate(table): \n",
    "                t = entry.text\n",
    "                t = re.sub(r\"\\s{2,}\",\"\",t)\n",
    "                if (idx+1) % self.n == 1: \n",
    "                    curr_name = t\n",
    "                elif (idx+1) % self.n == 2: \n",
    "                    curr_id = t \n",
    "                    if curr_id not in self.id_to_name:\n",
    "                        self.id_to_name[curr_id] = curr_name\n",
    "                    if parent_id is None: \n",
    "                        self.edges[0].append((None,curr_id))         \n",
    "                    else: \n",
    "                        self.edges[newlevel].append((parent_id,curr_id))\n",
    "                    curr_id, curr_name = None, None\n",
    "    \n",
    "    def process_descendents(self,filename):\n",
    "        self.n = 3 \n",
    "        while self.num_children() > 0:\n",
    "            self.edges[self.level+1] = [] \n",
    "            for p,curr in self.edges[self.level]: \n",
    "                if curr is None: continue \n",
    "                link = self.get_url(curr)\n",
    "                result = requests.get(link)\n",
    "                content = result.text\n",
    "                soup = BeautifulSoup(content, 'lxml')\n",
    "                self.get_info(soup,curr)\n",
    "                print(f\"Processed level {self.level+1} children of {self.id_to_name[curr]} ({curr})\")\n",
    "                with open(f\"../categories/{filename}\",\"w+\") as file: \n",
    "                    json.dump((self.edges,self.id_to_name),file)\n",
    "            self.level += 1 \n",
    "\n",
    "def process(parent_id, parent_name):\n",
    "    categories = Categories((parent_id,parent_name))\n",
    "    categories.process_descendents(f\"{parent_name}.json\")\n",
    "    print(categories.edges, \"\\n\", categories.id_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_id = '11059311'\n",
    "parent_name = \"Nail Art & Polish\"\n",
    "process(parent_id, parent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_id = '3764401'\n",
    "parent_name = \"Smoking Cessation\"\n",
    "process(parent_id, parent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_id = '7192394011'\n",
    "parent_name = \"Clothing, Shoes & Jewelry - Women - Jewelry\"\n",
    "process(parent_id, parent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_id = '3887881'\n",
    "parent_name = \"Clothing, Shoes & Jewelry - Men - Jewelry\"\n",
    "process(parent_id, parent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_id = '3880611'\n",
    "parent_name = \"Clothing, Shoes & Jewelry - Boys - Jewelry\"\n",
    "process(parent_id, parent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_id = '3880961'\n",
    "parent_name = \"Clothing, Shoes & Jewelry - Girls - Jewelry\"\n",
    "process(parent_id, parent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_id = '5524110011'\n",
    "parent_name = \"Musical Instruments - Instrument Accessories - Orchestral Strings Accessories & Parts\"\n",
    "process(parent_id, parent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine and translate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import pandas as pd \n",
    "all_id_to_name = {}\n",
    "levels = {}\n",
    "for filepath in os.listdir(f\"../categories\"): \n",
    "    if \"categories_graph.json\" in filepath or \".csv\" in filepath: continue\n",
    "    filepath = f\"../categories/{filepath}\"\n",
    "    with open(filepath,\"r\") as file: \n",
    "        edges,id_to_name = json.load(file)\n",
    "    all_id_to_name.update(id_to_name)\n",
    "    for level, edge_list in edges.items(): \n",
    "        for s,t in edge_list: \n",
    "            if t is not None:\n",
    "                if level not in levels:  levels[level] = {}\n",
    "                if s not in levels[level]: levels[level][s] = []\n",
    "                levels[level][s].append(t)\n",
    "\n",
    "names =[{\"name\":v} for k,v in all_id_to_name.items()]\n",
    "df = pd.DataFrame(names)\n",
    "df.to_csv(f\"../categories/names.csv\")\n",
    "with open(f\"../data/categories_graph.json\",\"w+\") as file:  \n",
    "    json.dump(levels,file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_id_to_name = []\n",
    "zh = pd.read_csv(\"../categories/translations.csv\")\n",
    "for idx, cat_id in enumerate(all_id_to_name):\n",
    "    name = all_id_to_name[cat_id]\n",
    "    trans = zh['name'][idx]\n",
    "    complete_id_to_name.append({\"id\":cat_id,\"name\":name,\"translation\":trans})\n",
    "df = pd.DataFrame(complete_id_to_name)\n",
    "df.to_csv(f\"../data/ID_TO_NAME.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations + relevant category ids & paths  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(f\"../data/ID_TO_NAME.csv\")\n",
    "all_id_to_name = {str(cat_id): data['name'][idx] for idx, cat_id in enumerate(data['id']) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def graph(filepath,figsize=(15,15),show=False):\n",
    "  with open(filepath,\"r\") as file: \n",
    "      edges,id_to_name = json.load(file)\n",
    "  G = nx.Graph() \n",
    "  for level, edgelist in edges.items(): \n",
    "    for e in edgelist: \n",
    "        if None in e: continue \n",
    "        i = (id_to_name[e[0]],e[0])\n",
    "        j = (id_to_name[e[1]],e[1])\n",
    "        G.add_edge(i,j) \n",
    "\n",
    "  if show: \n",
    "    plt.figure(figsize=figsize) \n",
    "    nx.draw(G,node_color=\"lightblue\",with_labels=True) \n",
    "    plt.show() \n",
    "  return G, id_to_name\n",
    "\n",
    "def find_node(target,id_to_name):\n",
    "    targets = []\n",
    "    for cat_id, name in id_to_name.items(): \n",
    "        if name == target:\n",
    "            targets.append(cat_id)\n",
    "    return targets  \n",
    "\n",
    "\n",
    "def bfs(G, source, target):\n",
    "    '''\n",
    "    source: (name, id) \n",
    "    target: id  \n",
    "    '''\n",
    "    queue = []\n",
    "    queue.append([source]) \n",
    "    while queue:\n",
    "        path = queue.pop(0)\n",
    "        node = path[-1]\n",
    "        if target in node:  \n",
    "            return path \n",
    "        for neighbor in nx.neighbors(G, node):\n",
    "            new_path = list(path)\n",
    "            new_path.append(neighbor)\n",
    "            queue.append(new_path)\n",
    "    return None \n",
    "\n",
    "def find_paths(source,keyword):\n",
    "    G, id_to_name = graph(f\"../categories/{all_id_to_name[source]}.json\")\n",
    "    root = (id_to_name[source],source)\n",
    "    targets = find_node(keyword,id_to_name)\n",
    "    paths = {}\n",
    "    for cat_id in targets: \n",
    "        path = bfs(G, root, cat_id)\n",
    "        print(path,\"\\n\")\n",
    "        final = path[-1]\n",
    "        paths[final[-1]] = path\n",
    "    return targets, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, id_to_name = graph(f\"../categories/{all_id_to_name['5524110011']}.json\",show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, id_to_name = graph(f\"../categories/{all_id_to_name['7192394011']}.json\",figsize=(25,25),show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, paths =  find_paths('5524110011','Violin')\n",
    "with open(f\"../data/categories/Violin.json\",\"w+\") as file: \n",
    "    json.dump((targets,paths),file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Smoking Cessation', '3764401'), ('Smokeless Inhalers', '4078751')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "targets, paths =  find_paths('3764401','Smokeless Inhalers')\n",
    "with open(f\"../data/categories/SmokelessInhalers.json\",\"w+\") as file: \n",
    "    json.dump((targets,paths),file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources =  ['7192394011','3887881','3880961','3880611']\n",
    "keywords = ['Bracelets','Necklaces','Rings','Anklets','Earrings',\n",
    "           'Brooches & Pins','Necklaces & Pendants',\n",
    "           'Wedding & Engagement','Body Jewelry','Jewelry Sets']\n",
    "\n",
    "search_ids = []\n",
    "search_paths = {}\n",
    "for s in sources: \n",
    "    for k in keywords: \n",
    "        targets, paths = find_paths(s,k)\n",
    "        search_ids.extend(targets)\n",
    "        search_paths.update(paths)\n",
    "\n",
    "with open(f\"../data/categories/Jewelry.json\",\"w+\") as file: \n",
    "    json.dump((search_ids,search_paths),file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json\n",
    "search_ids =  {}\n",
    "for filepath in os.listdir(f\"../data/categories\"): \n",
    "    filepath = f\"../data/categories/{filepath}\"\n",
    "    with open(filepath,\"r\") as file: \n",
    "        ids,paths = json.load(file)\n",
    "        for i, j in paths.items():\n",
    "            search_ids[i] = []\n",
    "            for k in j: \n",
    "                if k[1] != i: \n",
    "                    search_ids[i].append(k[1])\n",
    "with open(f\"../data/search_ids.json\",\"w+\") as file: \n",
    "    json.dump(search_ids,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prod_research3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
